#!/usr/bin/env python3
"""
Daily Review Command
åˆ†æå½“å‰æ—¥æœŸçš„æ—¥è®°æ–‡ä»¶å¹¶ç”Ÿæˆæ¯æ—¥æ€»ç»“çš„Pythonå®ç°ã€‚

Reviews the current day's markdown file content and updates the `## review` section
with a comprehensive summary including learning habits analysis and content insights.
"""

import sys
import os
import datetime
from typing import Dict, Optional

# æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥coreæ¨¡å—
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.date_utils import DateUtils
from core.file_utils import FileUtils
from core.content_parser import ContentParser
from core.templates import Templates


class DailyReviewAnalyzer:
    """æ¯æ—¥æ€»ç»“åˆ†æå™¨ã€‚"""

    def __init__(self, file_content: str):
        self.content = file_content
        self.sections = ContentParser.extract_all_sections(file_content)

    def analyze_learning_habits(self) -> Dict[str, any]:
        """åˆ†æå­¦ä¹ ä¹ æƒ¯ã€‚"""
        video_content = self.sections.get('video', '')
        newsletter_content = self.sections.get('newsletter', '')
        braindump_content = self.sections.get('braindump', '')
        output_content = self.sections.get('output', '')

        # è®¡ç®—å†…å®¹å¤šæ ·æ€§
        content_diversity = 0
        content_details = []

        if video_content:
            content_diversity += 1
            content_details.append("âœ… è§†é¢‘å­¦ä¹ ï¼šåŒ…å«å®ç”¨çš„å­¦ä¹ è§†é¢‘å†…å®¹")
        else:
            content_details.append("âšª è§†é¢‘å­¦ä¹ ï¼šä»Šæ—¥æœªè§‚çœ‹å­¦ä¹ è§†é¢‘")

        if newsletter_content:
            content_diversity += 1
            content_details.append("âœ… é˜…è¯»è¾“å…¥ï¼šå…³æ³¨è¡Œä¸šåŠ¨æ€å’ŒçŸ¥è¯†æ›´æ–°")
        else:
            content_details.append("âšª é˜…è¯»è¾“å…¥ï¼šä»Šæ—¥æœªè¿›è¡Œé˜…è¯»å­¦ä¹ ")

        if braindump_content:
            content_diversity += 1
            braindump_lines = ContentParser.count_section_items(self.content, 'braindump')
            if braindump_lines >= 3:
                content_details.append(f"âœ… æ·±åº¦æ€è€ƒï¼šè®°å½•äº†ä¸°å¯Œçš„æ€è€ƒå’Œæ´å¯Ÿ ({braindump_lines} æ¡)")
            else:
                content_details.append(f"âš ï¸ æ·±åº¦æ€è€ƒï¼šæœ‰æ€è€ƒè®°å½•ä½†ç›¸å¯¹è¾ƒå°‘ ({braindump_lines} æ¡)")
        else:
            content_details.append("âšª æ·±åº¦æ€è€ƒï¼šä»Šæ—¥ç¼ºå°‘æ€è€ƒå’Œæ´å¯Ÿè®°å½•")

        if output_content:
            content_diversity += 1
            content_details.append("âœ… å­¦ä¹ è¾“å‡ºï¼šæœ‰å®é™…çš„å­¦ä¹ æˆæœäº§å‡º")
        else:
            content_details.append("âšª å­¦ä¹ è¾“å‡ºï¼šä»Šæ—¥æœªäº§ç”Ÿå­¦ä¹ è¾“å‡º")

        # è®¡ç®—è¯„åˆ†
        habits_score = content_diversity * 25

        # ç”Ÿæˆå­¦ä¹ çŠ¶æ€è¯„ä»·
        if content_diversity >= 3:
            status = "ğŸ¯ **å­¦ä¹ çŠ¶æ€**: ä»Šæ—¥å­¦ä¹ å†…å®¹å‡è¡¡ï¼Œè¾“å…¥è¾“å‡ºå…¼å¤‡ï¼Œå­¦ä¹ ä¹ æƒ¯è‰¯å¥½"
        elif content_diversity >= 2:
            status = "ğŸ“ˆ **å­¦ä¹ çŠ¶æ€**: ä»Šæ—¥å­¦ä¹ æœ‰ä¸€å®šæˆæ•ˆï¼Œå»ºè®®è¡¥å……ç¼ºå¤±çš„å­¦ä¹ ç»´åº¦"
        else:
            status = "ğŸ”„ **å­¦ä¹ çŠ¶æ€**: ä»Šæ—¥å­¦ä¹ å†…å®¹è¾ƒå°‘ï¼Œå»ºè®®æ˜æ—¥åŠ å¼ºå­¦ä¹ æŠ•å…¥"

        return {
            'score': habits_score,
            'diversity': content_diversity,
            'details': content_details,
            'status': status
        }

    def extract_content_insights(self) -> str:
        """æå–å†…å®¹æ´å¯Ÿã€‚"""
        insights = []

        # æå–è§†é¢‘å­¦ä¹ é‡ç‚¹
        video_content = self.sections.get('video', '')
        if video_content:
            insights.append("**è§†é¢‘å­¦ä¹ é‡ç‚¹:**")
            lines = video_content.split('\n')
            video_items = [line for line in lines if line.strip().startswith('-')][:3]
            for item in video_items:
                insights.append(item)
            insights.append("")

        # æå–æ€è€ƒæ´å¯Ÿ
        braindump_content = self.sections.get('braindump', '')
        if braindump_content:
            lines = braindump_content.split('\n')
            key_insights = [line for line in lines if any(keyword in line for keyword in
                           ['æ´å¯Ÿ', 'å‘ç°', 'ä½“éªŒ', 'æ„Ÿå—', 'æ€»ç»“', 'æ€è€ƒ'])][:3]
            if key_insights:
                insights.append("**å…³é”®æ´å¯Ÿ:**")
                for insight in key_insights:
                    if insight.strip() and not insight.strip().startswith('='):
                        insights.append(f"- {insight.strip()}")
                insights.append("")

        # æå–é¡¹ç›®è¿›å±•
        output_content = self.sections.get('output', '')
        if output_content:
            insights.append("**å­¦ä¹ æˆæœ:**")
            lines = output_content.split('\n')[:3]
            for line in lines:
                if line.strip() and not line.strip().startswith('='):
                    insights.append(f"- {line.strip()}")
            insights.append("")

        return '\n'.join(insights) if insights else "ä»Šæ—¥å­¦ä¹ å†…å®¹è¾ƒä¸ºåŸºç¡€ï¼Œå»ºè®®å¢åŠ æ€è€ƒå’Œæ€»ç»“çš„æ·±åº¦ã€‚"

    def generate_recommendations(self, diversity: int) -> str:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®ã€‚"""
        recommendations = ["**æ˜æ—¥å»ºè®®:**"]

        if not self.sections.get('video'):
            recommendations.append("- ğŸ“¹ è€ƒè™‘è§‚çœ‹1-2ä¸ªæŠ€æœ¯ç›¸å…³è§†é¢‘æˆ–æ•™ç¨‹")

        if not self.sections.get('newsletter'):
            recommendations.append("- ğŸ“° é˜…è¯»è¡Œä¸šnewsletteræˆ–æŠ€æœ¯æ–‡ç« ")

        if not self.sections.get('braindump') or len(self.sections.get('braindump', '').split('\n')) < 3:
            recommendations.append("- ğŸ’­ å¢åŠ æ·±åº¦æ€è€ƒï¼Œè®°å½•æ›´å¤šæ´å¯Ÿå’Œæƒ³æ³•")

        if not self.sections.get('output'):
            recommendations.append("- ğŸ“ å°è¯•å°†å­¦ä¹ å†…å®¹è½¬åŒ–ä¸ºå…·ä½“è¾“å‡º")

        # åŸºäºå†…å®¹çš„ç‰¹å®šå»ºè®®
        braindump_content = self.sections.get('braindump', '')
        if braindump_content and 'äº§å“' in braindump_content:
            recommendations.append("- ğŸš€ ç»§ç»­æ·±åŒ–äº§å“æ€ç»´å’Œç”¨æˆ·ä½“éªŒæ€è€ƒ")

        if self.sections.get('output') and any(keyword in self.sections.get('output', '') for keyword in ['é¡¹ç›®', 'WayToAce']):
            recommendations.append("- ğŸ¯ æŒç»­æ¨è¿›é¡¹ç›®å…³é”®åŠŸèƒ½å¼€å‘")

        return '\n'.join(recommendations)


def main():
    """ä¸»å‡½æ•°ï¼Œæ‰§è¡Œdaily-reviewå‘½ä»¤é€»è¾‘ã€‚"""
    try:
        # è·å–å½“å‰æ—¥æœŸ
        current_date = DateUtils.get_current_date()

        # è·å–å½“å‰å‘¨çš„å‘¨ä¸€å’Œå‘¨æ—¥
        monday, sunday = DateUtils.get_week_range(current_date)

        # æ ¼å¼åŒ–å‘¨æ–‡ä»¶å¤¹åç§°å’Œæ—¥è®°æ–‡ä»¶è·¯å¾„
        folder_name = DateUtils.format_week_folder_name(monday, sunday)
        week_folder = FileUtils.get_week_folder_path(folder_name)
        daily_filename = DateUtils.format_daily_filename(current_date)
        daily_file_path = FileUtils.get_daily_file_path(week_folder, daily_filename)

        # æ£€æŸ¥æ—¥è®°æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not FileUtils.file_exists(daily_file_path):
            relative_path = FileUtils.get_relative_path(daily_file_path)
            print(f"Daily file does not exist: {relative_path}")
            print("Please run /daily-start first to create the daily file.")
            sys.exit(1)

        # è¯»å–æ–‡ä»¶å†…å®¹
        content = FileUtils.read_file(daily_file_path)
        if not content:
            print("Failed to read daily file content.")
            sys.exit(1)

        relative_path = FileUtils.get_relative_path(daily_file_path)
        print(f"Reading and analyzing content from: {relative_path}")

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰reviewç« èŠ‚
        if ContentParser.has_section(content, 'review'):
            print(f"Review section already exists in {relative_path}")
            print("Current content:")
            existing_review = ContentParser.extract_section(content, 'review')
            print(existing_review)
            print()

            # è¯¢é—®æ˜¯å¦é‡æ–°ç”Ÿæˆï¼ˆåœ¨å®é™…ä½¿ç”¨ä¸­å¯èƒ½éœ€è¦äº¤äº’å¼è¾“å…¥ï¼‰
            # è¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œç›´æ¥é‡æ–°ç”Ÿæˆ
            print("Regenerating review section...")
            content = ContentParser.remove_section(content, 'review')

        # åˆ†æå†…å®¹
        analyzer = DailyReviewAnalyzer(content)

        # æ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹å¯åˆ†æ
        if not any(analyzer.sections.values()):
            review_content = Templates.daily_review_template(
                "**ä»Šæ—¥å­¦ä¹ è®°å½•ä¸ºç©º**\n\nå»ºè®®æ˜æ—¥å¼€å§‹è®°å½•å­¦ä¹ å†…å®¹ã€‚",
                "",
                "",
                "å»ºè®®æ˜æ—¥è®°å½•ï¼š\n- ğŸ“¹ è§‚çœ‹çš„å­¦ä¹ è§†é¢‘\n- ğŸ“° é˜…è¯»çš„æ–‡ç« å’Œèµ„è®¯\n- ğŸ’­ æ€è€ƒå’Œæ´å¯Ÿè®°å½•\n- ğŸ“ å­¦ä¹ è¾“å‡ºå’Œé¡¹ç›®è¿›å±•"
            )
        else:
            # åˆ†æå­¦ä¹ ä¹ æƒ¯
            habits_analysis = analyzer.analyze_learning_habits()

            # ç”Ÿæˆæ´»åŠ¨æ€»ç»“
            activity_summary = []
            if analyzer.sections.get('video'):
                activity_summary.append("- **è§†é¢‘å­¦ä¹ **: è§‚çœ‹äº†æŠ€æœ¯ç›¸å…³è§†é¢‘å’Œæ•™ç¨‹å†…å®¹")

            if analyzer.sections.get('newsletter'):
                newsletter_items = ContentParser.extract_checkbox_items(content, 'newsletter')[1]
                activity_summary.append(f"- **æ–‡ç« é˜…è¯»**: å®Œæˆäº† {newsletter_items} é¡¹é˜…è¯»ä»»åŠ¡")

            if analyzer.sections.get('braindump'):
                braindump_items = ContentParser.count_section_items(content, 'braindump')
                activity_summary.append(f"- **æ·±åº¦æ€è€ƒ**: è®°å½•äº† {braindump_items} æ¡æ€è€ƒå’Œæ´å¯Ÿ")

            if analyzer.sections.get('output'):
                activity_summary.append("- **å­¦ä¹ è¾“å‡º**: äº§ç”Ÿäº†å…·ä½“çš„å­¦ä¹ æˆæœå’Œé¡¹ç›®è¿›å±•")

            activity_summary_text = '\n'.join(activity_summary) if activity_summary else "ä»Šæ—¥æš‚æ— å­¦ä¹ æ´»åŠ¨è®°å½•"

            # ç”Ÿæˆä¹ æƒ¯åˆ†ææ–‡æœ¬
            habits_text = f"å­¦ä¹ ä¹ æƒ¯è¯„ä¼° ({habits_analysis['score']}/100åˆ†):\n"
            habits_text += '\n'.join([f"- {detail}" for detail in habits_analysis['details']])
            habits_text += f"\n\n{habits_analysis['status']}"

            # æå–å†…å®¹æ´å¯Ÿ
            insights = analyzer.extract_content_insights()

            # ç”Ÿæˆå»ºè®®
            recommendations = analyzer.generate_recommendations(habits_analysis['diversity'])

            # ç”Ÿæˆreviewå†…å®¹
            review_content = Templates.daily_review_template(
                activity_summary_text,
                habits_text,
                insights,
                recommendations
            )

        # æ·»åŠ reviewç« èŠ‚åˆ°æ–‡ä»¶
        updated_content = content + review_content

        # å†™å…¥æ›´æ–°åçš„å†…å®¹
        FileUtils.write_file(daily_file_path, updated_content)

        print()
        print("âœ… Successfully added comprehensive daily review to", FileUtils.get_relative_path(daily_file_path))
        print()
        print("Review includes:")
        print("- ğŸ“Š Learning habits analysis with scoring")
        print("- ğŸ§  Key insights extraction from content")
        print("- ğŸ“ˆ Personalized recommendations for tomorrow")
        print("- ğŸ¯ Activity progress tracking")

    except Exception as e:
        print(f"Error generating daily review: {str(e)}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()